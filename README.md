# BACK
## BACK (Blind All Can Know) - Action Captioning for Blinds
อธิบายท่าทางการกระทำต่าง ๆ ที่อยู่ในรูปให้ออกมาเป็นคำบรรยาย เพื่อให้ผู้พิการทางสายตา สามารถรับรู้ได้ว่า ในภาพนี้กำลังเกิดอะไรขึ้นบ้าง!

อ่านทำความเข้าใจกับการทำงานได้ที่: https://medium.com/@cninet.std/back-blind-all-can-know-action-captioning-a10a3fa85695

## สำหรับการทำ Model ของเราจะใช้ Pre-trained Model ที่ชื่อว่า CLIP
สามารถเข้าถึงได้ที่: https://github.com/rmokady/CLIP_prefix_caption/

## ในส่วนของชุดข้อมูล Dataset เราเลือกใช้ Flickr
สามารถเข้าถึงได้ที่: https://www.kaggle.com/datasets/hsankesara/flickr-image-dataset

## อยากลองเล่นในฉบับโค้ดเต็ม ๆ สามารถกดที่ไฟล์ BACK.ipynb ในโน้ตบุ๊กนี้ได้เลย!
https://colab.research.google.com/github/cninet/BACK/blob/main/BACK.ipynb
เวลารันก็สามารถเลือก run all ได้เลย ผ่านฉลุย~!

### สำหรับใครที่อ่านตรงนี้แล้วดูแห้ง ๆ ไม่เข้าใจอะไรเลย แนะนำให้ไปอ่านใน Medium เพราะอธิบายไว้ละเอียดมาก!
